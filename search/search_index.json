{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"LanceOTron Command Line Interface A bare-bones interface to the trained LanceOTron (LoT) model from the command line. LoT is an all-in-one peak caller that identifies peak regions from a coverage track and uses a convolutional neural network to classify them based on their shape. This algorithm has a web client available at https://lanceotron.molbiol.ox.ac.uk/ where users can upload coverage tracks, call peaks, and visualize them using multi locus view , a powerful visualization engine. This web client will do most of the heavy lifting for most of the people that want to use the tool, but for those who need to call peaks in batch mode we provide a command line interface in this package. This document details the installation of LoT as well as typical use cases. See the left side of this page for tutorials on the three main modules. Installation Clone the repository. Install dependencies with pip. Install the package. Run tests to ensure that everything is working. git clone git@github.com:Chris1221/lanceotron.git; cd lanceotron # Step 1 pip install -r requirements.txt # Step 2 pip install -e . # Step 3 python -m unittest Usage To see available commands, use the --help flag. lanceotron --help Call Peaks To call peaks from a bigWig track, use the callPeaks command. Option Description Default file BigWig Track to analyse -t, --threshold Threshold for selecting candidate peaks 4 -w, --window Window size for rolling mean to select candidate peaks 400 -f, --folder Output folder \"./\" --skipheader Skip writing the header False Call Peaks with Input To call peaks from a bigWig track with an input file, use the callPeaks_Input command. Option Description Default file BigWig track to analyse -i, --input Control input track to calculate significance of peaks -t, --threshold Threshold for selecting candidate peaks 4 -w, --window Window size for rolling mean to select candidate peaks 400 -f, --folder Output folder \"./\" --skipheader Skip writing the header False Score a Bed file To score the peaks in an existing Bed file, use the scoreBed command. Option Description Default file BigWig Track to analyse -b, --bed Bed file of regions to be scored -f, --folder Output folder \"./\" --skipheader Skip writing the header False Examples There is a basic bigWig file included in the test subdirectory. To try out the caller, execute it on this file. lanceotron callPeaks test/chr22.bw -f output_folder Citation @article {Hentges2021.01.25.428108, author = {Hentges, Lance D. and Sergeant, Martin J. and Downes, Damien J. and Hughes, Jim R. and Taylor, Stephen}, title = {LanceOtron: a deep learning peak caller for ATAC-seq, ChIP-seq, and DNase-seq}, year = {2021}, doi = {10.1101/2021.01.25.428108}, publisher = {Cold Spring Harbor Laboratory}, URL = {https://www.biorxiv.org/content/early/2021/01/27/2021.01.25.428108}, journal = {bioRxiv} } Bug Reports and Improvement Suggestions Please raise an issue if there is anything you wish to ask or contribute.","title":"Overview"},{"location":"#lanceotron-command-line-interface","text":"A bare-bones interface to the trained LanceOTron (LoT) model from the command line. LoT is an all-in-one peak caller that identifies peak regions from a coverage track and uses a convolutional neural network to classify them based on their shape. This algorithm has a web client available at https://lanceotron.molbiol.ox.ac.uk/ where users can upload coverage tracks, call peaks, and visualize them using multi locus view , a powerful visualization engine. This web client will do most of the heavy lifting for most of the people that want to use the tool, but for those who need to call peaks in batch mode we provide a command line interface in this package. This document details the installation of LoT as well as typical use cases. See the left side of this page for tutorials on the three main modules.","title":"LanceOTron Command Line Interface"},{"location":"#installation","text":"Clone the repository. Install dependencies with pip. Install the package. Run tests to ensure that everything is working. git clone git@github.com:Chris1221/lanceotron.git; cd lanceotron # Step 1 pip install -r requirements.txt # Step 2 pip install -e . # Step 3 python -m unittest","title":"Installation"},{"location":"#usage","text":"To see available commands, use the --help flag. lanceotron --help","title":"Usage"},{"location":"#call-peaks","text":"To call peaks from a bigWig track, use the callPeaks command. Option Description Default file BigWig Track to analyse -t, --threshold Threshold for selecting candidate peaks 4 -w, --window Window size for rolling mean to select candidate peaks 400 -f, --folder Output folder \"./\" --skipheader Skip writing the header False","title":"Call Peaks"},{"location":"#call-peaks-with-input","text":"To call peaks from a bigWig track with an input file, use the callPeaks_Input command. Option Description Default file BigWig track to analyse -i, --input Control input track to calculate significance of peaks -t, --threshold Threshold for selecting candidate peaks 4 -w, --window Window size for rolling mean to select candidate peaks 400 -f, --folder Output folder \"./\" --skipheader Skip writing the header False","title":"Call Peaks with Input"},{"location":"#score-a-bed-file","text":"To score the peaks in an existing Bed file, use the scoreBed command. Option Description Default file BigWig Track to analyse -b, --bed Bed file of regions to be scored -f, --folder Output folder \"./\" --skipheader Skip writing the header False","title":"Score a Bed file"},{"location":"#examples","text":"There is a basic bigWig file included in the test subdirectory. To try out the caller, execute it on this file. lanceotron callPeaks test/chr22.bw -f output_folder","title":"Examples"},{"location":"#citation","text":"@article {Hentges2021.01.25.428108, author = {Hentges, Lance D. and Sergeant, Martin J. and Downes, Damien J. and Hughes, Jim R. and Taylor, Stephen}, title = {LanceOtron: a deep learning peak caller for ATAC-seq, ChIP-seq, and DNase-seq}, year = {2021}, doi = {10.1101/2021.01.25.428108}, publisher = {Cold Spring Harbor Laboratory}, URL = {https://www.biorxiv.org/content/early/2021/01/27/2021.01.25.428108}, journal = {bioRxiv} }","title":"Citation"},{"location":"#bug-reports-and-improvement-suggestions","text":"Please raise an issue if there is anything you wish to ask or contribute.","title":"Bug Reports and Improvement Suggestions"},{"location":"genome_tutorial/","text":"Call and Score Peaks This tutorial introduces the callPeaks module of Lanceotron. For a functional reference, developers can see documentation here .","title":"Basic Peak Calling"},{"location":"genome_tutorial/#call-and-score-peaks","text":"This tutorial introduces the callPeaks module of Lanceotron. For a functional reference, developers can see documentation here .","title":"Call and Score Peaks"},{"location":"api/modules/","text":"Module API Reference Need to document these functions. At the moment, they are only parameterised by the CLI. Make this into a splat pattern where the options are explicit with the function definition and not just with a dotdict Call peaks from a coverage track and score them using the LanceOTron model. Parameters: Name Type Description Default file str Path to bigwig track. required threshold int Initial threshold used for selecting candidate peaks. Defaults to 4. 4 window int Window size for rolling mean to use for selecting candidate peaks. Defaults to 400. 400 folder str Output folder. Defaults to \"./\". './' skipheader bool Skip writing header. Defaults to False. False Source code in lanceotron/modules.py def find_and_score_peaks ( file : str , threshold : int = 4 , window : int = 400 , folder : str = \"./\" , skipheader : bool = False ) -> None : \"\"\"Call peaks from a coverage track and score them using the LanceOTron model. Args: file (str): Path to bigwig track. threshold (int, optional): Initial threshold used for selecting candidate peaks. Defaults to 4. window (int, optional): Window size for rolling mean to use for selecting candidate peaks. Defaults to 400. folder (str, optional): Output folder. Defaults to \"./\". skipheader (bool, optional): Skip writing header. Defaults to False. \"\"\" bigwig_file = file out_folder = make_directory_name ( folder ) initial_threshold = threshold min_peak_width = 50 max_peak_width = 2000 read_coverage_factor = 10 ** 9 out_file_name = bigwig_file . split ( '/' )[ - 1 ] . split ( '.' )[ 0 ] + '_L-tron.bed' pyBigWig_object = pyBigWig . open ( bigwig_file ) read_coverage_total = pyBigWig_object . header ()[ 'sumData' ] read_coverage_rphm = read_coverage_total / read_coverage_factor pyBigWig_object . close () bigwig_data = Ltron . Bigwig_data ( bigwig_file ) genome_stats_dict = bigwig_data . get_genome_info () bed_file_out = [] for chrom in genome_stats_dict : print ( chrom ) coverage_array_smooth = bigwig_data . make_chrom_coverage_map ( genome_stats_dict [ chrom ], smoothing = window ) enriched_region_coord_list = Ltron . label_enriched_regions_dynamic_threshold_width ( coverage_array_smooth , genome_stats_dict [ chrom ][ 'chrom_mean' ] * initial_threshold , genome_stats_dict [ chrom ][ 'chrom_mean' ], max_peak_width , min_region_size = min_peak_width ) chrom_file_out = [] if enriched_region_coord_list : wide_path = pkg_resources . resource_filename ( 'lanceotron.static' , 'standard_scaler_wide_v5_03.p' ) deep_path = pkg_resources . resource_filename ( 'lanceotron.static' , 'standard_scaler_deep_v5_03.p' ) coverage_array = bigwig_data . make_chrom_coverage_map ( genome_stats_dict [ chrom ]) / read_coverage_rphm X_wide_array , X_deep_array = Ltron . extract_signal_wide_and_deep_chrom ( coverage_array , enriched_region_coord_list , read_coverage_rphm ) standard_scaler_wide = pickle . load ( open ( wide_path , 'rb' )) X_wide_array_norm = standard_scaler_wide . transform ( X_wide_array ) X_wide_array_norm = np . expand_dims ( X_wide_array_norm , axis = 2 ) standard_scaler = StandardScaler () X_deep_array_norm_T = standard_scaler . fit_transform ( X_deep_array . T ) standard_scaler_deep = pickle . load ( open ( deep_path , 'rb' )) X_deep_array_norm = standard_scaler_deep . transform ( X_deep_array_norm_T . T ) X_deep_array_norm = np . expand_dims ( X_deep_array_norm , axis = 2 ) model = build_model () model_classifications = model . predict ([ X_deep_array_norm , X_wide_array_norm ], verbose = 1 ) K . clear_session () for i , coord_pair in enumerate ( enriched_region_coord_list ): out_list = [ chrom , coord_pair [ 0 ], coord_pair [ 1 ], model_classifications [ 0 ][ i ][ 0 ], model_classifications [ 1 ][ i ][ 0 ], model_classifications [ 2 ][ i ][ 0 ]] X_wide_list = X_wide_array [ i ][: - 1 ] . tolist () X_wide_list = [ 100. if x > 10 else x for x in X_wide_list ] out_list += X_wide_list chrom_file_out . append ( out_list ) bed_file_out += chrom_file_out with open ( out_folder + out_file_name , 'w' , newline = '' ) as f : if not skipheader : f . write ( 'chrom \\t start \\t end \\t overall_peak_score \\t shape_score \\t enrichment_score \\t pvalue_chrom \\t pvalue_10kb \\t pvalue_20kb \\t pvalue_30kb \\t pvalue_40kb \\t pvalue_50kb \\t pvalue_60kb \\t pvalue_70kb \\t pvalue_80kb \\t pvalue_90kb \\t pvalue_100kb \\n ' ) bed_writer = csv . writer ( f , delimiter = ' \\t ' ) bed_writer . writerows ( bed_file_out ) Call peaks from a coverage track and score them using the LanceOTron model. Parameters: Name Type Description Default file str Path to bigwig track. required input str Control input track used to calculate Poisson-based significance of peaks. required threshold int Initial threshold used for selecting candidate peaks. Defaults to 4. 4 window int Window size for rolling mean to use for selecting candidate peaks. Defaults to 400. 400 folder str Output folder. Defaults to \"./\". './' skipheader bool Skip writing header. Defaults to False. False Source code in lanceotron/modules.py def call_peaks_with_input ( file : str , input : str , threshold : int = 4 , window : int = 400 , folder : str = \"./\" , skipheader : bool = False ) -> None : \"\"\"Call peaks from a coverage track and score them using the LanceOTron model. Args: file (str): Path to bigwig track. input (str): Control input track used to calculate Poisson-based significance of peaks. threshold (int, optional): Initial threshold used for selecting candidate peaks. Defaults to 4. window (int, optional): Window size for rolling mean to use for selecting candidate peaks. Defaults to 400. folder (str, optional): Output folder. Defaults to \"./\". skipheader (bool, optional): Skip writing header. Defaults to False. \"\"\" bigwig_file = file control_file = input out_folder = make_directory_name ( folder ) initial_threshold = threshold min_peak_width = 50 max_peak_width = 2000 read_coverage_factor = 10 ** 9 out_file_name = bigwig_file . split ( '/' )[ - 1 ] . split ( '.' )[ 0 ] + '_L-tron.bed' pyBigWig_object = pyBigWig . open ( bigwig_file ) read_coverage_total = pyBigWig_object . header ()[ 'sumData' ] read_coverage_rphm = read_coverage_total / read_coverage_factor pyBigWig_object . close () bigwig_data = Ltron . Bigwig_data ( bigwig_file ) genome_stats_dict = bigwig_data . get_genome_info () bed_file_out = [] for chrom in genome_stats_dict : print ( chrom ) coverage_array_smooth = bigwig_data . make_chrom_coverage_map ( genome_stats_dict [ chrom ], smoothing = window ) enriched_region_coord_list = Ltron . label_enriched_regions_dynamic_threshold_width ( coverage_array_smooth , genome_stats_dict [ chrom ][ 'chrom_mean' ] * initial_threshold , genome_stats_dict [ chrom ][ 'chrom_mean' ], max_peak_width , min_region_size = min_peak_width ) chrom_file_out = [] if enriched_region_coord_list : wide_path = pkg_resources . resource_filename ( 'lanceotron.static' , 'standard_scaler_wide_v5_03.p' ) deep_path = pkg_resources . resource_filename ( 'lanceotron.static' , 'standard_scaler_deep_v5_03.p' ) coverage_array = bigwig_data . make_chrom_coverage_map ( genome_stats_dict [ chrom ]) / read_coverage_rphm X_wide_array , X_deep_array = Ltron . extract_signal_wide_and_deep_chrom ( coverage_array , enriched_region_coord_list , read_coverage_rphm ) standard_scaler_wide = pickle . load ( open ( wide_path , 'rb' )) X_wide_array_norm = standard_scaler_wide . transform ( X_wide_array ) X_wide_array_norm = np . expand_dims ( X_wide_array_norm , axis = 2 ) standard_scaler = StandardScaler () X_deep_array_norm_T = standard_scaler . fit_transform ( X_deep_array . T ) standard_scaler_deep = pickle . load ( open ( deep_path , 'rb' )) X_deep_array_norm = standard_scaler_deep . transform ( X_deep_array_norm_T . T ) X_deep_array_norm = np . expand_dims ( X_deep_array_norm , axis = 2 ) model = build_model () model_classifications = model . predict ([ X_deep_array_norm , X_wide_array_norm ], verbose = 1 ) pyBigWig_input = pyBigWig . open ( control_file ) read_coverage_total_input = pyBigWig_input . header ()[ 'sumData' ] read_coverage_rphm_input = read_coverage_total_input / read_coverage_factor K . clear_session () for i , coord_pair in enumerate ( enriched_region_coord_list ): average_cov = coverage_array [ coord_pair [ 0 ]: coord_pair [ 1 ]] . mean () * read_coverage_rphm pvalue_input = calculate_pvalue_from_input ( chrom , coord_pair [ 0 ], coord_pair [ 1 ], read_coverage_total , read_coverage_total_input , pyBigWig_input , average_cov ) out_list = [ chrom , coord_pair [ 0 ], coord_pair [ 1 ], model_classifications [ 0 ][ i ][ 0 ], model_classifications [ 1 ][ i ][ 0 ], model_classifications [ 2 ][ i ][ 0 ], pvalue_input ] X_wide_list = X_wide_array [ i ][: - 1 ] . tolist () X_wide_list = [ 100. if x > 10 else x for x in X_wide_list ] out_list += X_wide_list chrom_file_out . append ( out_list ) pyBigWig_input . close () bed_file_out += chrom_file_out with open ( out_folder + out_file_name , 'w' , newline = '' ) as f : if not skipheader : f . write ( 'chrom \\t start \\t end \\t overall_peak_score \\t shape_score \\t enrichment_score \\t pvalue_input \\t pvalue_chrom \\t pvalue_10kb \\t pvalue_20kb \\t pvalue_30kb \\t pvalue_40kb \\t pvalue_50kb \\t pvalue_60kb \\t pvalue_70kb \\t pvalue_80kb \\t pvalue_90kb \\t pvalue_100kb \\n ' ) bed_writer = csv . writer ( f , delimiter = ' \\t ' ) bed_writer . writerows ( bed_file_out ) Score an existing bed file using LanceOTron's model and a coverage track. Parameters: Name Type Description Default file str Input bigWig track. required bed str Bed file of regions to score. required folder str Output folder. Defaults to \"./\". './' skipheader bool Skip writing header. Defaults to False. False Source code in lanceotron/modules.py def score_bed ( file : str , bed : str , folder : str = \"./\" , skipheader : bool = False ) -> None : \"\"\"Score an existing bed file using LanceOTron's model and a coverage track. Args: file (str): Input bigWig track. bed (str): Bed file of regions to score. folder (str): Output folder. Defaults to \"./\". skipheader (bool): Skip writing header. Defaults to False. \"\"\" bigwig_file = file out_folder = make_directory_name ( folder ) bed_file = bed read_coverage_factor = 10 ** 9 out_file_name = bigwig_file . split ( '/' )[ - 1 ] . split ( '.' )[ 0 ] + '_L-tron.bed' pyBigWig_object = pyBigWig . open ( bigwig_file ) read_coverage_total = pyBigWig_object . header ()[ 'sumData' ] read_coverage_rphm = read_coverage_total / read_coverage_factor pyBigWig_object . close () bed_list = Ltron . bed_file_to_list ( bed_file ) chroms_in_bed = [] for bed_entry in bed_list : if bed_entry [ 0 ] not in chroms_in_bed : chroms_in_bed . append ( bed_entry [ 0 ]) bigwig_data = Ltron . Bigwig_data ( bigwig_file ) genome_stats_dict = bigwig_data . get_genome_info ( include_special_chromosomes = True ) bed_file_out = [] for chrom in chroms_in_bed : print ( chrom ) enriched_region_coord_list = [] for bed_entry in bed_list : if bed_entry [ 0 ] == chrom : enriched_region_coord_list . append ([ bed_entry [ 1 ], bed_entry [ 2 ]]) chrom_file_out = [] if enriched_region_coord_list : wide_path = pkg_resources . resource_filename ( 'lanceotron.static' , 'standard_scaler_wide_v5_03.p' ) deep_path = pkg_resources . resource_filename ( 'lanceotron.static' , 'standard_scaler_deep_v5_03.p' ) coverage_array = bigwig_data . make_chrom_coverage_map ( genome_stats_dict [ chrom ]) / read_coverage_rphm X_wide_array , X_deep_array = Ltron . extract_signal_wide_and_deep_chrom ( coverage_array , enriched_region_coord_list , read_coverage_rphm ) standard_scaler_wide = pickle . load ( open ( wide_path , 'rb' )) X_wide_array_norm = standard_scaler_wide . transform ( X_wide_array ) X_wide_array_norm = np . expand_dims ( X_wide_array_norm , axis = 2 ) standard_scaler = StandardScaler () X_deep_array_norm_T = standard_scaler . fit_transform ( X_deep_array . T ) standard_scaler_deep = pickle . load ( open ( deep_path , 'rb' )) X_deep_array_norm = standard_scaler_deep . transform ( X_deep_array_norm_T . T ) X_deep_array_norm = np . expand_dims ( X_deep_array_norm , axis = 2 ) model = build_model () model_classifications = model . predict ([ X_deep_array_norm , X_wide_array_norm ], verbose = 1 ) K . clear_session () for i , coord_pair in enumerate ( enriched_region_coord_list ): out_list = [ chrom , coord_pair [ 0 ], coord_pair [ 1 ], model_classifications [ 0 ][ i ][ 0 ], model_classifications [ 1 ][ i ][ 0 ], model_classifications [ 2 ][ i ][ 0 ]] X_wide_list = X_wide_array [ i ][: - 1 ] . tolist () X_wide_list = [ 100. if x > 10 else x for x in X_wide_list ] out_list += X_wide_list chrom_file_out . append ( out_list ) bed_file_out += chrom_file_out with open ( out_folder + out_file_name , 'w' , newline = '' ) as f : if not skipheader : f . write ( 'chrom \\t start \\t end \\t overall_peak_score \\t shape_score \\t enrichment_score \\t pvalue_chrom \\t pvalue_10kb \\t pvalue_20kb \\t pvalue_30kb \\t pvalue_40kb \\t pvalue_50kb \\t pvalue_60kb \\t pvalue_70kb \\t pvalue_80kb \\t pvalue_90kb \\t pvalue_100kb \\n ' ) bed_writer = csv . writer ( f , delimiter = ' \\t ' ) bed_writer . writerows ( bed_file_out )","title":"Modules"},{"location":"api/modules/#module-api-reference","text":"Need to document these functions. At the moment, they are only parameterised by the CLI. Make this into a splat pattern where the options are explicit with the function definition and not just with a dotdict Call peaks from a coverage track and score them using the LanceOTron model. Parameters: Name Type Description Default file str Path to bigwig track. required threshold int Initial threshold used for selecting candidate peaks. Defaults to 4. 4 window int Window size for rolling mean to use for selecting candidate peaks. Defaults to 400. 400 folder str Output folder. Defaults to \"./\". './' skipheader bool Skip writing header. Defaults to False. False Source code in lanceotron/modules.py def find_and_score_peaks ( file : str , threshold : int = 4 , window : int = 400 , folder : str = \"./\" , skipheader : bool = False ) -> None : \"\"\"Call peaks from a coverage track and score them using the LanceOTron model. Args: file (str): Path to bigwig track. threshold (int, optional): Initial threshold used for selecting candidate peaks. Defaults to 4. window (int, optional): Window size for rolling mean to use for selecting candidate peaks. Defaults to 400. folder (str, optional): Output folder. Defaults to \"./\". skipheader (bool, optional): Skip writing header. Defaults to False. \"\"\" bigwig_file = file out_folder = make_directory_name ( folder ) initial_threshold = threshold min_peak_width = 50 max_peak_width = 2000 read_coverage_factor = 10 ** 9 out_file_name = bigwig_file . split ( '/' )[ - 1 ] . split ( '.' )[ 0 ] + '_L-tron.bed' pyBigWig_object = pyBigWig . open ( bigwig_file ) read_coverage_total = pyBigWig_object . header ()[ 'sumData' ] read_coverage_rphm = read_coverage_total / read_coverage_factor pyBigWig_object . close () bigwig_data = Ltron . Bigwig_data ( bigwig_file ) genome_stats_dict = bigwig_data . get_genome_info () bed_file_out = [] for chrom in genome_stats_dict : print ( chrom ) coverage_array_smooth = bigwig_data . make_chrom_coverage_map ( genome_stats_dict [ chrom ], smoothing = window ) enriched_region_coord_list = Ltron . label_enriched_regions_dynamic_threshold_width ( coverage_array_smooth , genome_stats_dict [ chrom ][ 'chrom_mean' ] * initial_threshold , genome_stats_dict [ chrom ][ 'chrom_mean' ], max_peak_width , min_region_size = min_peak_width ) chrom_file_out = [] if enriched_region_coord_list : wide_path = pkg_resources . resource_filename ( 'lanceotron.static' , 'standard_scaler_wide_v5_03.p' ) deep_path = pkg_resources . resource_filename ( 'lanceotron.static' , 'standard_scaler_deep_v5_03.p' ) coverage_array = bigwig_data . make_chrom_coverage_map ( genome_stats_dict [ chrom ]) / read_coverage_rphm X_wide_array , X_deep_array = Ltron . extract_signal_wide_and_deep_chrom ( coverage_array , enriched_region_coord_list , read_coverage_rphm ) standard_scaler_wide = pickle . load ( open ( wide_path , 'rb' )) X_wide_array_norm = standard_scaler_wide . transform ( X_wide_array ) X_wide_array_norm = np . expand_dims ( X_wide_array_norm , axis = 2 ) standard_scaler = StandardScaler () X_deep_array_norm_T = standard_scaler . fit_transform ( X_deep_array . T ) standard_scaler_deep = pickle . load ( open ( deep_path , 'rb' )) X_deep_array_norm = standard_scaler_deep . transform ( X_deep_array_norm_T . T ) X_deep_array_norm = np . expand_dims ( X_deep_array_norm , axis = 2 ) model = build_model () model_classifications = model . predict ([ X_deep_array_norm , X_wide_array_norm ], verbose = 1 ) K . clear_session () for i , coord_pair in enumerate ( enriched_region_coord_list ): out_list = [ chrom , coord_pair [ 0 ], coord_pair [ 1 ], model_classifications [ 0 ][ i ][ 0 ], model_classifications [ 1 ][ i ][ 0 ], model_classifications [ 2 ][ i ][ 0 ]] X_wide_list = X_wide_array [ i ][: - 1 ] . tolist () X_wide_list = [ 100. if x > 10 else x for x in X_wide_list ] out_list += X_wide_list chrom_file_out . append ( out_list ) bed_file_out += chrom_file_out with open ( out_folder + out_file_name , 'w' , newline = '' ) as f : if not skipheader : f . write ( 'chrom \\t start \\t end \\t overall_peak_score \\t shape_score \\t enrichment_score \\t pvalue_chrom \\t pvalue_10kb \\t pvalue_20kb \\t pvalue_30kb \\t pvalue_40kb \\t pvalue_50kb \\t pvalue_60kb \\t pvalue_70kb \\t pvalue_80kb \\t pvalue_90kb \\t pvalue_100kb \\n ' ) bed_writer = csv . writer ( f , delimiter = ' \\t ' ) bed_writer . writerows ( bed_file_out ) Call peaks from a coverage track and score them using the LanceOTron model. Parameters: Name Type Description Default file str Path to bigwig track. required input str Control input track used to calculate Poisson-based significance of peaks. required threshold int Initial threshold used for selecting candidate peaks. Defaults to 4. 4 window int Window size for rolling mean to use for selecting candidate peaks. Defaults to 400. 400 folder str Output folder. Defaults to \"./\". './' skipheader bool Skip writing header. Defaults to False. False Source code in lanceotron/modules.py def call_peaks_with_input ( file : str , input : str , threshold : int = 4 , window : int = 400 , folder : str = \"./\" , skipheader : bool = False ) -> None : \"\"\"Call peaks from a coverage track and score them using the LanceOTron model. Args: file (str): Path to bigwig track. input (str): Control input track used to calculate Poisson-based significance of peaks. threshold (int, optional): Initial threshold used for selecting candidate peaks. Defaults to 4. window (int, optional): Window size for rolling mean to use for selecting candidate peaks. Defaults to 400. folder (str, optional): Output folder. Defaults to \"./\". skipheader (bool, optional): Skip writing header. Defaults to False. \"\"\" bigwig_file = file control_file = input out_folder = make_directory_name ( folder ) initial_threshold = threshold min_peak_width = 50 max_peak_width = 2000 read_coverage_factor = 10 ** 9 out_file_name = bigwig_file . split ( '/' )[ - 1 ] . split ( '.' )[ 0 ] + '_L-tron.bed' pyBigWig_object = pyBigWig . open ( bigwig_file ) read_coverage_total = pyBigWig_object . header ()[ 'sumData' ] read_coverage_rphm = read_coverage_total / read_coverage_factor pyBigWig_object . close () bigwig_data = Ltron . Bigwig_data ( bigwig_file ) genome_stats_dict = bigwig_data . get_genome_info () bed_file_out = [] for chrom in genome_stats_dict : print ( chrom ) coverage_array_smooth = bigwig_data . make_chrom_coverage_map ( genome_stats_dict [ chrom ], smoothing = window ) enriched_region_coord_list = Ltron . label_enriched_regions_dynamic_threshold_width ( coverage_array_smooth , genome_stats_dict [ chrom ][ 'chrom_mean' ] * initial_threshold , genome_stats_dict [ chrom ][ 'chrom_mean' ], max_peak_width , min_region_size = min_peak_width ) chrom_file_out = [] if enriched_region_coord_list : wide_path = pkg_resources . resource_filename ( 'lanceotron.static' , 'standard_scaler_wide_v5_03.p' ) deep_path = pkg_resources . resource_filename ( 'lanceotron.static' , 'standard_scaler_deep_v5_03.p' ) coverage_array = bigwig_data . make_chrom_coverage_map ( genome_stats_dict [ chrom ]) / read_coverage_rphm X_wide_array , X_deep_array = Ltron . extract_signal_wide_and_deep_chrom ( coverage_array , enriched_region_coord_list , read_coverage_rphm ) standard_scaler_wide = pickle . load ( open ( wide_path , 'rb' )) X_wide_array_norm = standard_scaler_wide . transform ( X_wide_array ) X_wide_array_norm = np . expand_dims ( X_wide_array_norm , axis = 2 ) standard_scaler = StandardScaler () X_deep_array_norm_T = standard_scaler . fit_transform ( X_deep_array . T ) standard_scaler_deep = pickle . load ( open ( deep_path , 'rb' )) X_deep_array_norm = standard_scaler_deep . transform ( X_deep_array_norm_T . T ) X_deep_array_norm = np . expand_dims ( X_deep_array_norm , axis = 2 ) model = build_model () model_classifications = model . predict ([ X_deep_array_norm , X_wide_array_norm ], verbose = 1 ) pyBigWig_input = pyBigWig . open ( control_file ) read_coverage_total_input = pyBigWig_input . header ()[ 'sumData' ] read_coverage_rphm_input = read_coverage_total_input / read_coverage_factor K . clear_session () for i , coord_pair in enumerate ( enriched_region_coord_list ): average_cov = coverage_array [ coord_pair [ 0 ]: coord_pair [ 1 ]] . mean () * read_coverage_rphm pvalue_input = calculate_pvalue_from_input ( chrom , coord_pair [ 0 ], coord_pair [ 1 ], read_coverage_total , read_coverage_total_input , pyBigWig_input , average_cov ) out_list = [ chrom , coord_pair [ 0 ], coord_pair [ 1 ], model_classifications [ 0 ][ i ][ 0 ], model_classifications [ 1 ][ i ][ 0 ], model_classifications [ 2 ][ i ][ 0 ], pvalue_input ] X_wide_list = X_wide_array [ i ][: - 1 ] . tolist () X_wide_list = [ 100. if x > 10 else x for x in X_wide_list ] out_list += X_wide_list chrom_file_out . append ( out_list ) pyBigWig_input . close () bed_file_out += chrom_file_out with open ( out_folder + out_file_name , 'w' , newline = '' ) as f : if not skipheader : f . write ( 'chrom \\t start \\t end \\t overall_peak_score \\t shape_score \\t enrichment_score \\t pvalue_input \\t pvalue_chrom \\t pvalue_10kb \\t pvalue_20kb \\t pvalue_30kb \\t pvalue_40kb \\t pvalue_50kb \\t pvalue_60kb \\t pvalue_70kb \\t pvalue_80kb \\t pvalue_90kb \\t pvalue_100kb \\n ' ) bed_writer = csv . writer ( f , delimiter = ' \\t ' ) bed_writer . writerows ( bed_file_out ) Score an existing bed file using LanceOTron's model and a coverage track. Parameters: Name Type Description Default file str Input bigWig track. required bed str Bed file of regions to score. required folder str Output folder. Defaults to \"./\". './' skipheader bool Skip writing header. Defaults to False. False Source code in lanceotron/modules.py def score_bed ( file : str , bed : str , folder : str = \"./\" , skipheader : bool = False ) -> None : \"\"\"Score an existing bed file using LanceOTron's model and a coverage track. Args: file (str): Input bigWig track. bed (str): Bed file of regions to score. folder (str): Output folder. Defaults to \"./\". skipheader (bool): Skip writing header. Defaults to False. \"\"\" bigwig_file = file out_folder = make_directory_name ( folder ) bed_file = bed read_coverage_factor = 10 ** 9 out_file_name = bigwig_file . split ( '/' )[ - 1 ] . split ( '.' )[ 0 ] + '_L-tron.bed' pyBigWig_object = pyBigWig . open ( bigwig_file ) read_coverage_total = pyBigWig_object . header ()[ 'sumData' ] read_coverage_rphm = read_coverage_total / read_coverage_factor pyBigWig_object . close () bed_list = Ltron . bed_file_to_list ( bed_file ) chroms_in_bed = [] for bed_entry in bed_list : if bed_entry [ 0 ] not in chroms_in_bed : chroms_in_bed . append ( bed_entry [ 0 ]) bigwig_data = Ltron . Bigwig_data ( bigwig_file ) genome_stats_dict = bigwig_data . get_genome_info ( include_special_chromosomes = True ) bed_file_out = [] for chrom in chroms_in_bed : print ( chrom ) enriched_region_coord_list = [] for bed_entry in bed_list : if bed_entry [ 0 ] == chrom : enriched_region_coord_list . append ([ bed_entry [ 1 ], bed_entry [ 2 ]]) chrom_file_out = [] if enriched_region_coord_list : wide_path = pkg_resources . resource_filename ( 'lanceotron.static' , 'standard_scaler_wide_v5_03.p' ) deep_path = pkg_resources . resource_filename ( 'lanceotron.static' , 'standard_scaler_deep_v5_03.p' ) coverage_array = bigwig_data . make_chrom_coverage_map ( genome_stats_dict [ chrom ]) / read_coverage_rphm X_wide_array , X_deep_array = Ltron . extract_signal_wide_and_deep_chrom ( coverage_array , enriched_region_coord_list , read_coverage_rphm ) standard_scaler_wide = pickle . load ( open ( wide_path , 'rb' )) X_wide_array_norm = standard_scaler_wide . transform ( X_wide_array ) X_wide_array_norm = np . expand_dims ( X_wide_array_norm , axis = 2 ) standard_scaler = StandardScaler () X_deep_array_norm_T = standard_scaler . fit_transform ( X_deep_array . T ) standard_scaler_deep = pickle . load ( open ( deep_path , 'rb' )) X_deep_array_norm = standard_scaler_deep . transform ( X_deep_array_norm_T . T ) X_deep_array_norm = np . expand_dims ( X_deep_array_norm , axis = 2 ) model = build_model () model_classifications = model . predict ([ X_deep_array_norm , X_wide_array_norm ], verbose = 1 ) K . clear_session () for i , coord_pair in enumerate ( enriched_region_coord_list ): out_list = [ chrom , coord_pair [ 0 ], coord_pair [ 1 ], model_classifications [ 0 ][ i ][ 0 ], model_classifications [ 1 ][ i ][ 0 ], model_classifications [ 2 ][ i ][ 0 ]] X_wide_list = X_wide_array [ i ][: - 1 ] . tolist () X_wide_list = [ 100. if x > 10 else x for x in X_wide_list ] out_list += X_wide_list chrom_file_out . append ( out_list ) bed_file_out += chrom_file_out with open ( out_folder + out_file_name , 'w' , newline = '' ) as f : if not skipheader : f . write ( 'chrom \\t start \\t end \\t overall_peak_score \\t shape_score \\t enrichment_score \\t pvalue_chrom \\t pvalue_10kb \\t pvalue_20kb \\t pvalue_30kb \\t pvalue_40kb \\t pvalue_50kb \\t pvalue_60kb \\t pvalue_70kb \\t pvalue_80kb \\t pvalue_90kb \\t pvalue_100kb \\n ' ) bed_writer = csv . writer ( f , delimiter = ' \\t ' ) bed_writer . writerows ( bed_file_out )","title":"Module API Reference"}]}